{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG System for SEC 10-K Financial Question Answering\n",
    "\n",
    "This notebook implements a complete Retrieval-Augmented Generation (RAG) system that answers financial questions from Apple's FY2024 and Tesla's FY2023 10-K filings.\n",
    "\n",
    "**Colab-Ready**: Click \"Run all\" or execute cells sequentially.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup & Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Check if running in Colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    print(\"✓ Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"✓ Running locally (not Colab)\")\n",
    "\n",
    "# Set working directory\n",
    "if IN_COLAB:\n",
    "    REPO_DIR = \"/content/SecRAG-10K\"\n",
    "else:\n",
    "    REPO_DIR = os.getcwd()\n",
    "\n",
    "print(f\"Working directory: {REPO_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone GitHub repository (Colab only)\n",
    "if IN_COLAB:\n",
    "    os.chdir(\"/content\")\n",
    "    if not os.path.exists(REPO_DIR):\n",
    "        print(\"Cloning repository from GitHub...\")\n",
    "        subprocess.run(\n",
    "            [\"git\", \"clone\", \"https://github.com/kalpeshdahake/SecRAG-10K.git\"],\n",
    "            check=True\n",
    "        )\n",
    "    os.chdir(REPO_DIR)\n",
    "    print(f\"✓ Repository ready at {REPO_DIR}\")\n",
    "else:\n",
    "    print(\"✓ Local mode - using existing directory\")\n",
    "\n",
    "# Verify structure\n",
    "required_dirs = [\"data\", \"ingestion\", \"embeddings\", \"retrieval\", \"llm\", \"pipeline\"]\n",
    "for dir_name in required_dirs:\n",
    "    if os.path.exists(dir_name):\n",
    "        print(f\"  ✓ {dir_name}/\")\n",
    "    else:\n",
    "        print(f\"  ✗ {dir_name}/ MISSING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "print(\"Installing dependencies...\")\n",
    "subprocess.run(\n",
    "    [sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\", \"--quiet\"],\n",
    "    check=False\n",
    ")\n",
    "print(\"✓ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Verify Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test imports\n",
    "print(\"Testing imports...\")\n",
    "\n",
    "try:\n",
    "    import pypdf\n",
    "    print(\"  ✓ pypdf\")\n",
    "except ImportError as e:\n",
    "    print(f\"  ✗ pypdf: {e}\")\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    print(\"  ✓ sentence-transformers\")\n",
    "except ImportError as e:\n",
    "    print(f\"  ✗ sentence-transformers: {e}\")\n",
    "\n",
    "try:\n",
    "    import chromadb\n",
    "    print(\"  ✓ chromadb\")\n",
    "except ImportError as e:\n",
    "    print(f\"  ✗ chromadb: {e}\")\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"  ✓ torch (GPU available: {torch.cuda.is_available()})\")\n",
    "except ImportError as e:\n",
    "    print(f\"  ✗ torch: {e}\")\n",
    "\n",
    "try:\n",
    "    from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "    print(\"  ✓ transformers\")\n",
    "except ImportError as e:\n",
    "    print(f\"  ✗ transformers: {e}\")\n",
    "\n",
    "print(\"\\n✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PDF Indexing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Load & Parse PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ingestion modules\n",
    "import sys\n",
    "sys.path.insert(0, REPO_DIR)\n",
    "\n",
    "from ingestion.pdf_loader import load_pdf\n",
    "from ingestion.section_parser import assign_items\n",
    "from ingestion.chunker import chunk_text\n",
    "\n",
    "print(\"Loading PDFs...\")\n",
    "\n",
    "# Load Apple 10-K\n",
    "apple_pages = load_pdf(\n",
    "    \"data/10-Q4-2024-As-Filed.pdf\",\n",
    "    company=\"Apple\",\n",
    "    document=\"Apple 10-K\"\n",
    ")\n",
    "apple_pages = assign_items(apple_pages)\n",
    "apple_chunks = chunk_text(apple_pages)\n",
    "\n",
    "print(f\"Apple 10-K: {len(apple_pages)} pages → {len(apple_chunks)} chunks\")\n",
    "print(f\"  Sample metadata: {apple_chunks[0]['metadata']}\")\n",
    "\n",
    "# Load Tesla 10-K\n",
    "tesla_pages = load_pdf(\n",
    "    \"data/tsla-20231231-gen.pdf\",\n",
    "    company=\"Tesla\",\n",
    "    document=\"Tesla 10-K\"\n",
    ")\n",
    "tesla_pages = assign_items(tesla_pages)\n",
    "tesla_chunks = chunk_text(tesla_pages)\n",
    "\n",
    "print(f\"\\nTesla 10-K: {len(tesla_pages)} pages → {len(tesla_chunks)} chunks\")\n",
    "print(f\"  Sample metadata: {tesla_chunks[0]['metadata']}\")\n",
    "\n",
    "print(f\"\\n✓ Total chunks: {len(apple_chunks) + len(tesla_chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Generate Embeddings & Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embeddings.embedder import Embedder\n",
    "from embeddings.vector_store import VectorStore\n",
    "\n",
    "print(\"Initializing embedding model & vector store...\")\n",
    "\n",
    "# Initialize embedder and vector store\n",
    "embedder = Embedder()\n",
    "vector_store = VectorStore(persist_dir=\"vector_db\")\n",
    "\n",
    "# Create collections\n",
    "apple_collection = vector_store.get_or_create_collection(\"apple_10k\")\n",
    "tesla_collection = vector_store.get_or_create_collection(\"tesla_10k\")\n",
    "\n",
    "print(\"✓ Collections created\")\n",
    "print(\"\\nGenerating Apple embeddings...\")\n",
    "\n",
    "# Embed Apple chunks\n",
    "apple_embeddings = embedder.embed_texts(\n",
    "    [chunk[\"text\"] for chunk in apple_chunks]\n",
    ")\n",
    "vector_store.add_chunks(apple_collection, apple_chunks, apple_embeddings)\n",
    "\n",
    "print(f\"✓ Apple indexed: {len(apple_chunks)} chunks\")\n",
    "\n",
    "print(\"\\nGenerating Tesla embeddings...\")\n",
    "\n",
    "# Embed Tesla chunks\n",
    "tesla_embeddings = embedder.embed_texts(\n",
    "    [chunk[\"text\"] for chunk in tesla_chunks]\n",
    ")\n",
    "vector_store.add_chunks(tesla_collection, tesla_chunks, tesla_embeddings)\n",
    "\n",
    "print(f\"✓ Tesla indexed: {len(tesla_chunks)} chunks\")\n",
    "\n",
    "print(\"\\n✓ Indexing complete! Ready for inference.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Inference & Evaluation\n",
    "\n",
    "Run the RAG pipeline on all 13 test questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Test Question Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 13 test questions from assignment\n",
    "test_questions = [\n",
    "    {\"question_id\": 1, \"question\": \"What was Apple's total revenue for the fiscal year ended September 28, 2024?\"},\n",
    "    {\"question_id\": 2, \"question\": \"How many shares of common stock were issued and outstanding as of October 18, 2024?\"},\n",
    "    {\"question_id\": 3, \"question\": \"What is the total amount of term debt (current + non-current) reported by Apple as of September 28, 2024?\"},\n",
    "    {\"question_id\": 4, \"question\": \"On what date was Apple's 10-K report for 2024 signed and filed with the SEC?\"},\n",
    "    {\"question_id\": 5, \"question\": \"Does Apple have any unresolved staff comments from the SEC as of this filing? How do you know?\"},\n",
    "    {\"question_id\": 6, \"question\": \"What was Tesla's total revenue for the year ended December 31, 2023?\"},\n",
    "    {\"question_id\": 7, \"question\": \"What percentage of Tesla's total revenue in 2023 came from Automotive Sales (excluding Leasing)?\"},\n",
    "    {\"question_id\": 8, \"question\": \"What is the primary reason Tesla states for being highly dependent on Elon Musk?\"},\n",
    "    {\"question_id\": 9, \"question\": \"What types of vehicles does Tesla currently produce and deliver?\"},\n",
    "    {\"question_id\": 10, \"question\": \"What is the purpose of Tesla's 'lease pass-through fund arrangements'?\"},\n",
    "    {\"question_id\": 11, \"question\": \"What is Tesla's stock price forecast for 2025?\"},\n",
    "    {\"question_id\": 12, \"question\": \"Who is the CFO of Apple as of 2025?\"},\n",
    "    {\"question_id\": 13, \"question\": \"What color is Tesla's headquarters painted?\"}\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(test_questions)} test questions\")\n",
    "for q in test_questions[:3]:\n",
    "    print(f\"  Q{q['question_id']}: {q['question'][:60]}...\")\n",
    "print(f\"  ... and {len(test_questions) - 3} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Run RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.rag_pipeline import answer_question\n",
    "\n",
    "print(\"Running RAG pipeline on test questions...\\n\")\n",
    "\n",
    "# Combined collection for routing\n",
    "combined_collection = {\n",
    "    \"apple\": apple_collection,\n",
    "    \"tesla\": tesla_collection\n",
    "}\n",
    "\n",
    "# Helper: Route to correct collection\n",
    "def answer_with_routing(query):\n",
    "    q_lower = query.lower()\n",
    "    if \"apple\" in q_lower:\n",
    "        return answer_question(query, apple_collection)\n",
    "    elif \"tesla\" in q_lower:\n",
    "        return answer_question(query, tesla_collection)\n",
    "    else:\n",
    "        return {\n",
    "            \"answer\": \"This question cannot be answered based on the provided documents.\",\n",
    "            \"sources\": []\n",
    "        }\n",
    "\n",
    "# Run on all questions\n",
    "results = []\n",
    "\n",
    "for q in test_questions:\n",
    "    qid = q[\"question_id\"]\n",
    "    query = q[\"question\"]\n",
    "\n",
    "    result = answer_with_routing(query)\n",
    "\n",
    "    output = {\n",
    "        \"question_id\": qid,\n",
    "        \"answer\": result[\"answer\"],\n",
    "        \"sources\": result[\"sources\"]\n",
    "    }\n",
    "\n",
    "    results.append(output)\n",
    "\n",
    "    print(f\"Q{qid}: {query[:70]}...\")\n",
    "    print(f\"  Answer: {result['answer'][:80]}...\")\n",
    "    print(f\"  Sources: {result['sources']}\\n\")\n",
    "\n",
    "print(\"✓ All 13 questions processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to JSON\n",
    "output_file = \"results.json\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"✓ Results saved to {output_file}\")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "answered = sum(1 for r in results if \"cannot be answered\" not in r[\"answer\"].lower())\n",
    "refused = len(results) - answered\n",
    "\n",
    "print(f\"\\nQuestions Answered: {answered}/13\")\n",
    "print(f\"Questions Refused: {refused}/13\")\n",
    "\n",
    "print(\"\\nAnswered:\")\n",
    "for r in results:\n",
    "    if \"cannot be answered\" not in r[\"answer\"].lower():\n",
    "        print(f\"  Q{r['question_id']}: {r['answer'][:60]}... [{r['sources']}]\")\n",
    "\n",
    "print(\"\\nRefused (Out-of-Scope):\")\n",
    "for r in results:\n",
    "    if \"cannot be answered\" in r[\"answer\"].lower():\n",
    "        print(f\"  Q{r['question_id']}: {r['answer'][:60]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Interactive Query Mode\n",
    "\n",
    "Ask custom questions about the 10-K filings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom query function\n",
    "def query_rag(question):\n",
    "    \"\"\"\n",
    "    Query the RAG system with a custom question.\n",
    "\n",
    "    Args:\n",
    "        question (str): Your question about Apple or Tesla 10-K\n",
    "\n",
    "    Returns:\n",
    "        dict: {\"answer\": str, \"sources\": list}\n",
    "    \"\"\"\n",
    "    result = answer_with_routing(question)\n",
    "    return result\n",
    "\n",
    "# Example custom queries\n",
    "print(\"Custom Query Examples:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "custom_queries = [\n",
    "    \"What are Apple's main business segments?\",\n",
    "    \"What risks does Tesla face?\"\n",
    "]\n",
    "\n",
    "for query in custom_queries:\n",
    "    result = query_rag(query)\n",
    "    print(f\"Q: {query}\")\n",
    "    print(f\"A: {result['answer']}\")\n",
    "    print(f\"Sources: {result['sources']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Download Results\n",
    "\n",
    "Save results locally (Colab only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    print(\"Downloading results.json...\")\n",
    "    files.download(\"results.json\")\n",
    "    print(\"✓ Download started\")\n",
    "else:\n",
    "    print(\"Local mode: results saved to ./results.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
